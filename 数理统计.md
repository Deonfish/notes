# 数理统计

## 基础知识

#### 随机变量X

一个变量的取值是随机的，不可以由一定条件确定的，而只可以研究他的概率，这样的变量叫做随机变量。如，掷骰子得到的点数X，只可以得到X的概率而不可以由别的值求出X。
与随机变量相对的即为“确定性变量”。如，我开车t小时内走的路程 $d=\int vdt$ ，是可以根据v和t直接确定。

#### 总体

把研究对象的全体称为总体，总体是客观存在的事物的集合。但我们主要研究的是总体某一个指标，把这个指标取为X，例如所有中国人中一个人的身高，则这个指标是一个随机变量，研究这个随机变量的分布情况即实现了对总体特征的研究。（所以总体的随机变量 X 往往是总体中某一个个体的指标，和样本有些相似）

#### 样本

从总体中随机取出一个数据，这个数据称为一个样本，设这个数据是一个随机变量X（这个数据已经可以测出来，但是把它设为未知数），则它和总体同分布。如，从所有中国人中取出100个人的身高，则他们作为随机变量为 $X_1,...,X_{100}$ 
[注] 样本在数理统计中常常当作已知量。

#### 分布函数

对于随机变量X，任意实数t
$$
F(t)=P(X\le t)
$$
称为随机变量X的分布函数，此处的t与X无关，是任取的数。

#### 离散X的分布列

对于离散随机变量X，所有可能取值是$t_1, t_2, ...$ ，则称X取 $t_i$ 的概率
$$
p_i=p(t_i)=p(X=t_i)
$$
为X的分布列。其中$t_i$为X的具体取值。

#### 连续的密度函数

若对于可积函数p(t)，对任意实数x有
$$
F(x)=\int_{-\infty}^x p(t)\ dt
$$
则称p(t)为密度函数。其中的t、x均与X无关，为任意数。

#### 随机变量的数学期望

对于离散随机变量X：
$$
E(g(X))=\sum_{i=0}^\infty g(t_i)\cdot p(t_i),\quad其中t_i为X的所有kennel的取值
$$
对于连续型随机变量：
$$
E(g(X))=\int_{-\infty}^{+\infty}g(t)\cdot f(t)\ dt
$$

#### 随机变量的方差

$$
Var(X)=E(X-E(X))^2
$$



定义式肯定不会比这个式子简单
$$
Var(X)=E(X^2)-[E(X)]^2
$$

#### 条件数学期望

对于离散随机变量X，Y
$$
\mathrm{E}(X \mid Y=y)=\sum_{x \in \mathcal{X}} x \mathrm{P}(X=x \mid Y=y)=\sum_{x \in \mathcal{X}} x \frac{\mathrm{P}(X=x, Y=y)}{\mathrm{P}(Y=y)}
$$
其中，$\chi$ 是处于![X](https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab)的值域。

对于连续X，离散Y
$$
\mathrm{E}(X \mid Y=y)=\int_{\mathcal{X}} x f_{X}(x \mid Y=y) d x
$$



#### 统计量

样本均值
$$
\overline{X}=\frac{1}{n}\sum_{i=0}^n x_i
$$
样本方差
$$
S^2=\frac{1}{n-1}\sum_{i=1}^n (x_i-\overline{X})
$$
统计量的均值、方差
$$
E(\overline{X})=E(X),\ E(S^2)=Var(X) \\
Var(\overline{X})=\frac{Var(X)}{n}
$$

#### 分位数

若有
$$
P\{ X \leq x_p \}=p
$$
则称 $x_p$ 为此分布的p分位数。对于密度函数对称的分布，有 $-z_p=z_{1-p}$ 

## 假设检验

### 参数假设检验

假设检验求参数估计：对于参数的一个估计，给出其成立的概率（落入接受域的概率）。

假设参数的值 $H_0:\theta \in \Theta_0， H_1:\theta \in \Theta_1$ ，构造一个统计量 z (不含未知参数)来作为参数的估计，若这个统计量与原假设偏差太大，则拒绝原假设。规定一个临界值 c (常数)(c代表偏差的大小)，则确定出拒绝域：$W=\{ \ (x_1,\dots,x_n): \ |z|\geq c \ \}$ （拒绝域形式与备择假设一致），若样本落在拒绝域内，则拒绝原假设。（在这个步骤中自变量都是样本，其他都是常数）

> 例，客服单位时间内接到的电话数量X服从泊松分布$P(\lambda)$ ，参数未知。估计参数的范围为（假设为）：$H_0: \lambda \leq 1,\ H_1: \lambda > 1$ ，取检验统计量 $T=\sum X_i$ ，因为T是$\lambda$的充分、完备统计量，当假设成立时T不会太大。对于一个给定的临界值c，有拒绝域$W=\{ x:\sum x_i \geq c \}$ 。落入拒绝域的概率可用蒙特卡洛模拟求得。

若 $P_{\Theta_0}\{(x_1, ..., x_n) \in W\} \leq \alpha$ 则称该检验是一个水平为 $\alpha$ 的检验，称所有 $\alpha$ 中最小的、或 $ P_{\Theta_0}\{(x_1, ..., x_n) \in W\} \leq \alpha $ 的上确界 $sup\{P_{\Theta_0}\{(x_1, ..., x_n) \in W\}\}$ 为检验的真实水平。而显著水平 $\alpha$ 下的拒绝域通常指 $sup\{P_{\Theta_0}\{(x_1, ..., x_n) \in W\}\}$ 即显著水平 $\alpha$ 下最大的拒绝域。

第一类错误定义为，当原假设成立（拒绝域很小）（可忽略此条件），样本观测值却落入拒绝域。
犯一类错误的概率为：$p=P_{\theta}\{ x \in W \},\quad \theta \in \Theta_0$ 。
二类错误定义为，当原假设不成立（拒绝域很大）（可忽略此条件），样本观测值没落在拒绝域。
犯二类错误的概率为：$p=P_{\theta}\{ x \in W^c \}=1-P_{\theta}\{ x \in W \},\quad \theta \in \Theta_1$ 

对于一个检验（假设和拒绝域确定一个检验），定义检验的势函数：样本在任意参数假设下落在拒绝域的概率 $g(\theta) = P_\theta(x \in W), \theta \in \Theta$ 
（势函数是一个一对多的函数，因为一个参数$\theta$ 对应多个由不同拒绝域W确定出的假设，对应不同的拒绝域概率）

##### 拒绝域

确定一个统计量$T(x)$ ，其大小可以表征在假设成立的条件下，样本数据与假设的参数的偏差(eg. 假设$\mu=\mu_0$成立下 ，$T(x)=|\bar{x}-\mu_0｜$可以表征偏差大小 )。给定一个常数c，把样本当作自变量，样本空间被划分为两部分：
$$
拒绝域：\quad W=\{ \ (x_1,\dots,x_n): \ T(x)\geq c \ \} \\
接受域: \quad W^c=\{ \ (x_1,\dots,x_n): \ T(x)< c \ \} \\
$$
其中，拒绝域的偏差过大。

##### 检验函数

$$
\varphi(x)=\begin{cases}1,& x \in W \\
0,& x \notin W
\end{cases}
$$

拒绝域上的示性函数。

[注] $P_\theta \{ x \in W \}=E(\varphi(x))$ - 落入拒绝域的概率

##### 第一类错误

由于样本的随机性，原假设H0原本成立，代入的样本值却落入了拒绝域W（n组样本值，少数几组落入了拒绝域），犯一类错误的概率为：
$$
p=P_{\theta}\{ x \in W \},\quad \theta \in \Theta_0
$$
[注]此概率表达式中并没有蕴含"原假设已经成立"这一结论，这个结论是把样本组代入得到的结论。

##### 第二类错误

原假设H0本来不成立(H1成立)，样本观察值落入了接受域$W^c$，发生的概率为：
$$
p=P_{\theta}\{ x \in W^c \}=1-P_{\theta}\{ x \in W \},\quad \theta \in \Theta_1
$$

##### 一个检验的势

H0不成立时拒绝H0的概率（可以理解为接受原假设的概率）
$$
p=P_{\theta}\{ x \in W \},\quad \theta \in \Theta_1
$$

##### 势函数

样本观察值落入拒绝域的概率为势函数。其中自变量为参数、对应与某种假设。
$$
g(\theta)=P_\theta\{ x \in W \},\quad \theta \in \Theta
$$
在这个意义下，犯一类错误的概率为
$$
g(\theta_0)=P_{\theta}\{ x \in W \},\quad \theta \in \Theta_0
$$
犯二类错误的概率为
$$
1-g(\theta_1)=1-P_{\theta}\{ x \in W \},\quad \theta \in \Theta_1
$$
一个检验的势为
$$
g(\theta_1)=P_{\theta}\{ x \in W \},\quad \theta \in \Theta_1
$$

##### p值

确定检验统计量z以后，对一组确定的样本观察值，代入可以得到 $z_0$ 值，把概率 $P\{ |z| \geq |z_0| \}$ 称为p值，它表示把样本观察值代入得到的值当作检验的临界值c后得到的真实显著性水平。所以p值即为估计的显著性水平，p值越大，估计越好，拒绝域越小。
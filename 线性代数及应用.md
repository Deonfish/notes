## 矩阵代数

### 矩阵乘法

行列法则：

$AB$ 的第 $i$ 行第 $j$ 列元素 $a_{ij}$ 是 $A$ 的第 $i$ 行与 $B$ 的第 $j$ 列对应元素乘积

 特殊乘法：

1. 向量·向量

$$
\vec{\alpha}^{T} \times \vec{\beta} =x \space\space(行\times列=标量) \\ 
\vec{\alpha} \times \vec{\beta}^{T} =A\space\space (列\times行=矩阵) \\
其中，矩阵 \ A=(b_{1}\vec{\alpha} ,\  b_{2}\vec{\alpha} ,...)
$$

2. 矩阵·向量

$$
B\overrightarrow{x}=x_{1}\overrightarrow{b_{1}} + x_{2}\overrightarrow{b_{2}}+...+x_{n}\overrightarrow{b_{n}} \\
乘积为矩阵\ B\ 列向量的线性组合，组合系数为向量 \vec{x} 的系数
$$

3. 矩阵·矩阵

$$
AB=(Ab_{1},\ Ab_{2},\ ...\ , Ab_{n}) \\
即乘积\ AB\ 的每一个列向量为矩阵\ A\ 列向量的线性组合
$$

### 分块矩阵

#### 分块矩阵的乘法

要求矩阵A的列分法与B的行分法一致，A的行分法与B的列分法随意。
$$
A\times B=\begin{bmatrix} A_{11}&A_{12}\\A_{21}&A_{22} \end{bmatrix}\times \begin{bmatrix} B_1\\B_2 \end{bmatrix}
$$


#### A·B 的行列展开

$$
AB=\begin{bmatrix} \vec{a_1}&\ \vec{a_2}&\ \dots \end{bmatrix}\times \begin{bmatrix} \vec{b_1}^T\\ \vec{b_2}^T\\ \vdots \end{bmatrix}=\vec{a_1}\vec{b_1}^T+\vec{a_2}\vec{b_2}^T+\dots 
$$



### 矩阵的零空间和列空间

#### 零空间

定义：矩阵 $A_{m\times n}$ ，满足 $A\vec{x}=0$ 的所有向量 $\vec{x}$ 的集合为A的零空间，记为$Null\ A$

零空间是 $\mathbb R^n$ 的子空间，即零空间中的所有向量长度为n

从矩阵A不可以直接得到 $Null\ A$ ，需要解方程 $Ax=0$

核一定包含零向量0

#### 列空间

定义：A的所有列向量张成的空间，记为 $Col\ A$

列空间是 $\mathbb R^m$ 的子空间，即列空间中的所有向量是m维的

#### 列空间与零空间的对比

若把A看作一个线性变换 $A\vec{x}=\vec{y}$ ，则核 $Null\ A$ 为定义域中被变换为0的向量集合，列空间 $Col\ A$ 为线性变换的值域。

<img src="/Users/guosongnan/Desktop/working/notes/pic/线性变换.png" alt="线性变换" style="zoom:24%;" />

### 秩定理

A为 $m\times n$ 矩阵
$$
dim(ColA)+dim(NullA)=n
$$

## 向量空间

### 线性空间

空间的维数：空间中基向量的个数
[注] 空间中，向量的长度 $\leq$ 空间的维数

### 线性变换

$$
A\times \vec{x}=\vec{y}
$$

做了一个空间变换，把向量 $\vec{x}$ 变换为 $\vec{y}$ ，而矩阵 $A$ 是变换后空间的基。

注意，此处变换的是向量本身。

### 坐标变换

设存在n维空间的基矩阵 $B=\begin{bmatrix} b_1&b_2&\dots \end{bmatrix} $，计算向量 $\vec{x}$ 在B空间的坐标 $[\ x\ ]_B$ 
$$
[\ \vec{x}\ ]_B=B^{-1}\times [\ \vec{x}\ ]_{直角坐标系}
$$

> 例，一个向量为 $\vec{x}=(2,2)$ ，B空间基为 $\vec{i}=(2,0), \vec{j}=(0,2)$  ，则计算出坐标为 $(1,1)$

此处的 $\vec{x}$ 可以理解为向量在直角坐标系下的坐标，于是该变换是直角坐标系下的坐标到另一个基底生成空间的线性变换。

注意，此处变换的是坐标而不是向量本身，不要用向量去理解坐标，坐标为标量。



## 特征向量&特征值

方阵才会有特征值&特征向量。
因为若是非方阵，有 $A_{m\times n}\times \vec{x_n} = \vec{x_m}$ 矛盾。 
从线性变换的角度讲，线性变换 $A_{m\times n}$ 变换后得到的向量 $\vec{x_m}$ 和 $\vec{x_n}$ 长度不一样

[注] 特征向量为一组向量，若 $\vec{v}$ 为特征向量，则 $k\vec{v}$ 为特征向量（特征空间）。通常说“几个”特征向量意思是有几组线性无关的特征向量。

### 特征值&向量与线性映射

对于矩阵A，若把它理解成线性变换T，则特征向量 $\vec{v}$ 为线性变换T的定义域中被映射成自己的 $\lambda$ 倍的向量，而特征值是此映射的倍数。

所以在这个意义下，特征向量标识了线性空间变换中方向不变的向量，特征值表示该向量伸缩的倍数。

**特征值的个数：** n阶矩阵A，有n个特征值（其中包含重根与复数根）。
**特征向量个数：** 若特征值的重数为k，则每个特征值对应 1～k 个特征值。 矩阵A最多有n个特征值，即 所有特征空间维数 $\leq$ n。

[注] 其实对于m重特征值 $\lambda$ ，若有k个线性无关的特征向量，则 $\lambda$ 真实的重数应该为 k，只是为了方便表示为m重。

一些特殊的矩阵：

- 剪切变换 $\begin{bmatrix} 1&1 \\ 0&1 \end{bmatrix}$ 的特征值为1(二重根)， 特征向量只有一个 $\begin{pmatrix} 1,0 \end{pmatrix}$ 。

  -- 重根对应一个特征向量

- 旋转矩阵 $\begin{bmatrix} 0&-1 \\ 1&0 \end{bmatrix}$ 的特征值为复数 $i,-i$ ，特征向量为复向量？
  -- 复根对应旋转

- 缩放矩阵 $\begin{bmatrix} 2&0 \\ 0&2 \end{bmatrix}$ 的特征值为2(重根)，特征向量为任意两个二维向量。
  -- 重根对应两个特征向量

### 相似

